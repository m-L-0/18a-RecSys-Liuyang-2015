{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于用户的协同过滤算法\n",
    "\n",
    "# Author : MilesCode\n",
    "# Date : 18/03/29\n",
    "# Version : 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miles/.virtualenvs/env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "import random\n",
    "\n",
    "\n",
    "def load_data(filename,data):\n",
    "    with open(filename,'r') as f:  \n",
    "        for line in f.readlines():  \n",
    "            line = line.strip()\n",
    "            linelist = line.split()\n",
    "#             data.append()\n",
    "            data.append([linelist[0],linelist[1]])\n",
    "#         print(data)\n",
    "#             linelist = map(int,linestrlist)# 方法一  \n",
    "#             linelist = [int(i) for i in linestrlist] # 方法二  \n",
    "#             data.append(linestrlist[])\n",
    "#             print(linelist)\n",
    "# def ReadData(file, data):\n",
    "#     ''' 读取评分数据\n",
    "#         @param file  评分数据文件\n",
    "#         @param data 储存评分数据的List\n",
    "#     '''\n",
    "#     for line in file:\n",
    "#         print(line)\n",
    "#         line = line.strip('\\n')\n",
    "#         linelist = line.split()\n",
    "#         print(linelist)\n",
    "#         data.append([linelist[0], linelist[1]])\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "filename = 'ml-100k/u.data'\n",
    "load_data(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(x, y):\n",
    "    \"\"\"\n",
    "    计算余弦相似度\n",
    "\n",
    "    Args:\n",
    "    - x: mat, 以行向量的形式存储\n",
    "    - y: mat, 以行向量的形式存储\n",
    "\n",
    "    :return: x 和 y 之间的余弦相似度\n",
    "    \"\"\"\n",
    "    \n",
    "    numerator = x * y.T  # x 和 y 之间的内积\n",
    "    denominator = np.sqrt(x * x.T) * np.sqrt(y * y.T)\n",
    "    return (numerator / denominator)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(data):\n",
    "    \"\"\"\n",
    "    计算矩阵中任意两行之间的相似度\n",
    "\n",
    "    Args:\n",
    "    - data: mat, 任意矩阵\n",
    "\n",
    "    :return: w, mat, 任意两行之间的相似度\n",
    "    \"\"\"\n",
    "\n",
    "    m = np.shape(data)[0]  # 用户的数量\n",
    "    # 初始化相似矩阵\n",
    "    w = np.mat(np.zeros((m, m)))\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(i, m):\n",
    "            if not j == i:\n",
    "                # 计算任意两行之间的相似度\n",
    "                w[i, j] = cos_sim(data[i, ], data[j, ])\n",
    "                w[j, i] = w[i, j]\n",
    "            else:\n",
    "                w[i, j] = 0\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_recommend(data, w, user):\n",
    "    \"\"\"\n",
    "    基于用户相似度为用户 user 推荐物品\n",
    "\n",
    "    Args:\n",
    "    - data: mat, 用户物品矩阵\n",
    "    - w: mat, 用户之间的相似度\n",
    "    - user: int, 用户编号\n",
    "\n",
    "    :return: predict, list, 推荐列表\n",
    "    \"\"\"\n",
    "    m, n = np.shape(data)\n",
    "    interaction = data[user, ]  # 用户 user 与物品信息\n",
    "\n",
    "    # 找到用户 user 没有互动过的物品\n",
    "    not_inter = []\n",
    "    for i in range(n):\n",
    "        if interaction[0, i] == 0:  # 没有互动的物品\n",
    "            not_inter.append(i)\n",
    "\n",
    "    # 对没有互动过的物品进行预测\n",
    "    predict = {}\n",
    "    for x in not_inter:\n",
    "        item = np.copy(data[:, x])  # 找到所有用户对商品 x 的互动信息\n",
    "        for i in range(m):  # 对每一个用户\n",
    "            if item[i, 0] != 0:\n",
    "                if x not in predict:\n",
    "                    predict[x] = w[user, i] * item[i, 0]\n",
    "                else:\n",
    "                    predict[x] = predict[x] + w[user, i] + item[i, 0]\n",
    "    return sorted(predict.items(), key=lambda d: d[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(data, M, key, seed):\n",
    "    ''' 将数据分为训练集和测试集\n",
    "        @param data   储存训练和测试数据的List\n",
    "        @param M      将数据分为M份\n",
    "        @param key    选取第key份数据做为测试数据\n",
    "        @param seed   随机种子\n",
    "        @return train 训练数据集Dict\n",
    "        @return test  测试数据集Dict\n",
    "    '''\n",
    "    test = dict()\n",
    "    train = dict()\n",
    "    random.seed(seed)\n",
    "    for user, item in data:\n",
    "        if random.randint(0, M) == key:\n",
    "            if user in test:\n",
    "                test[user].append(item)\n",
    "            else:\n",
    "                test[user] = []\n",
    "        else:\n",
    "            if user in train:\n",
    "                train[user].append(item)\n",
    "            else:\n",
    "                train[user] = []\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(train, test, N):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in train.keys():\n",
    "        tu = test[user]\n",
    "        rank = Recommend(user, N)\n",
    "        for item, pui in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += len(tu)\n",
    "    return hit / (all * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(train, test, N):\n",
    "    hit = 0\n",
    "    all = 0\n",
    "    for user in train.keys():\n",
    "        tu = test[user]\n",
    "        rank = Recommend(user, N)\n",
    "        for item, pui in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all += N\n",
    "    return hit / (all * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coverage(train, test, N):\n",
    "    recommend_items = set()\n",
    "    all_items = set()\n",
    "    for user in train.keys():\n",
    "        for item in train[user].keys():\n",
    "            all_items.add(item)\n",
    "        rank = Recommend(user, N)\n",
    "        for item, pui in rank:\n",
    "            recommend_items.add(item)\n",
    "    return len(recommend_items) / (len(all_items) * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Popularity(train, test, N):\n",
    "    item_popularity = dict()\n",
    "    for user, items in train.items():\n",
    "        for item in items.keys():\n",
    "            if item not in item_popularity:\n",
    "                item_popularity[item] = 0\n",
    "            item_popularity[item] += 1\n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in train.keys():\n",
    "        rank = Recommend(user, N)\n",
    "        for item, pui in rank:\n",
    "            ret += math.log(1 + item_popularity[item])\n",
    "            n += 1\n",
    "    ret /= n * 1.0\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def UserSimilarity(train):\n",
    "#     # build inverse table for item_users\n",
    "#     item_users = dict()\n",
    "#     for u, items in train.items():\n",
    "#         for i in items.keys():\n",
    "#             if i not in item_users:\n",
    "#                 item_users[i] = set()\n",
    "#             item_users[i].add(u)\n",
    "#     #calculate co-rated items between users\n",
    "#         C = dict()\n",
    "#         N = dict()\n",
    "#         for i, users in item_users.items():\n",
    "#             for u in users:\n",
    "#                 N[u] += 1\n",
    "#                 for v in users:\n",
    "#                     if u == v:\n",
    "#                         continue\n",
    "#                     C[u][v] += 1\n",
    "#     #calculate finial similarity matrix W\n",
    "#     W = dict()\n",
    "#     for u, related_users in C.items():\n",
    "#         for v, cuv in related_users.items():\n",
    "#             W[u][v] = cuv / math.sqrt(N[u] * N[v])\n",
    "#     return W\n",
    "\n",
    "def UserSimilarity(train):\n",
    "    ''' 计算用户相似度\n",
    "        @param train 训练数据集Dict\n",
    "        @return W    记录用户相似度的二维矩阵\n",
    "    '''\n",
    "    #建立物品到用户之间的倒查表，降低计算用户相似度的时间复杂性\n",
    "    item_users = dict()\n",
    "    for u, items in train.items():\n",
    "        for i in items:\n",
    "            if (i not in item_users):\n",
    "                item_users[i] = set()\n",
    "            item_users[i].add(u)\n",
    "        C = dict()\n",
    "        N = dict()\n",
    "        #计算用户之间共有的item的数目\n",
    "        for i, users in item_users.items():\n",
    "            for u in users:\n",
    "                if (u not in N):\n",
    "                    N[u] = 1\n",
    "                N[u] += 1\n",
    "                for v in users:\n",
    "                    if u == v:\n",
    "                        continue\n",
    "                    if (u not in C):\n",
    "                        C[u] = dict()\n",
    "                    if (v not in C[u]):\n",
    "                        C[u][v] = 0\n",
    "                    #对热门物品进行了惩罚，采用这种方法被称做UserCF-IIF\n",
    "                    C[u][v] += (1 / math.log(1 + len(users)))\n",
    "    W = dict()\n",
    "    for u, related_users in C.items():\n",
    "        for v, cuv in related_users.items():\n",
    "            if (u not in W):\n",
    "                W[u] = dict()\n",
    "            #利用余弦相似度计算用户之间的相似度\n",
    "            W[u][v] = cuv / math.sqrt(N[u] * N[v])\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommend(user, train, W, N, K):\n",
    "    rank = dict()\n",
    "    interacted_items = train[user]\n",
    "    for v, wuv in sorted(W[user].items(), key=itemgetter(1), reverse=True)[0:K]:\n",
    "        for i, rvi in train[v].items:\n",
    "            if i in interacted_items:\n",
    "    #we should filter items user interacted before\n",
    "                continue\n",
    "            rank[i] += wuv * rvi\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Running...\n",
      "1\n",
      "200\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'196'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-71b64f5902bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUserSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-483172e7abd3>\u001b[0m in \u001b[0;36mRecall\u001b[0;34m(train, test, N)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpui\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '196'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = []\n",
    "    M = 8\n",
    "    key = 10\n",
    "    seed = 1\n",
    "    N = 10\n",
    "\n",
    "    print(\"Process Running...\")\n",
    "    file = 'ml-100k/u.data'\n",
    "    load_data(file, data)\n",
    "    train, test = SplitData(data, M, key, seed)\n",
    "    print(1)\n",
    "    W = UserSimilarity(train)\n",
    "    print(2)\n",
    "    recall = Recall(train, test, N)\n",
    "    print(3)\n",
    "    precision = Precision(train, test, N)\n",
    "    print(4)\n",
    "    popularity = Popularity(train, test, N)\n",
    "    print(5)\n",
    "    coverage = Coverage(train, test,N)\n",
    "    print(6)\n",
    "    print('recall: ', recall, '\\n')\n",
    "    print('precision: ', precision, '\\n')\n",
    "    print('Popularity: ', popularity, '\\n')\n",
    "    print('coverage: ', coverage, '\\n')\n",
    "else:\n",
    "    print(\"this is not the main function\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
